{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import gzip\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Weights matrix  and biases vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 784), (10, 100)] and [(100, 1), (10, 1)]\n"
     ]
    }
   ],
   "source": [
    "sizes = [784, 100, 10]\n",
    "\n",
    "num_layers = len(sizes)\n",
    "\n",
    "biases = [np.random.randn(y, 1) for y in sizes[1:]]\n",
    "weights = [np.random.randn(y, x) for x, y in zip(sizes[:-1], sizes[1:])]\n",
    "\n",
    "print([w.shape for w in weights], 'and', [b.shape for b in biases])\n",
    "\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1.0/(1.0 + np.exp(-z))\n",
    "\n",
    "\n",
    "def feedforward(a):\n",
    "    for b, w in zip(biases, weights):\n",
    "        a = sigmoid(np.dot(w, a) + b)\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(100, 784), (10, 100)] and [(100, 1), (10, 1)]\n"
     ]
    }
   ],
   "source": [
    "print([w.shape for w in weights], 'and', [b.shape for b in biases])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "inv = np.zeros((784, 1))\n",
    "\n",
    "res = feedforward(inv)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.37, 0.35, 0.00, 0.95, 0.03, 0.99, 0.15, 0.99, 1.00, 0.09]\n"
     ]
    }
   ],
   "source": [
    "print(np.array2string(res.reshape((-1,)), separator=', ', formatter={'float_kind': lambda x: f'{x:0.2f}'}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    with gzip.open('data/mnist.pkl.gz', 'rb') as f:\n",
    "        train_data, valid_data, test_data = pickle.load(f, encoding='latin1')\n",
    "    \n",
    "    return train_data, valid_data, test_data\n",
    "\n",
    "\n",
    "train_data, valid_data, test_data = load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50000, 784), (50000,)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[t.shape for t in train_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, y_train = train_data\n",
    "x_valid, y_valid = valid_data\n",
    "x_test, y_test = test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, ..., 8, 4, 8])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_categorical(x):\n",
    "    num_categories = np.unique(x).shape[0]\n",
    "    vector = np.eye(num_categories, dtype='uint8')[x]\n",
    "    return vector.reshape((-1, 10, 1))\n",
    "\n",
    "yy_train = to_categorical(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 10, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [1]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]] 5\n"
     ]
    }
   ],
   "source": [
    "print(yy_train[0], y_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 784)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx_train = x_train.reshape((-1, 784, 1))\n",
    "xx_test = x_test.reshape((-1, 784, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = np.random.randint(x_train.shape[0])\n",
    "plt.imshow(x_train[idx].reshape((28, 28)))\n",
    "plt.title(f'digit: {y_train[idx]}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 1 0 0 0 0]] 5\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.randint(yy_train.shape[0])\n",
    "\n",
    "print(yy_train[idx].transpose(), y_train[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SGD\n",
    "Train the neural network using mini-batch stochastic gradient descent.  The `training_data` is a list of tuples\n",
    "`(x, y)` representing the training inputs and the desired outputs.  The other non-optional parameters are self-explanatory.  If `test_data` is provided then the network will be evaluated against the test data after each epoch, and partial progress printed out.  This is useful for tracking progress, but slows things down substantially.\n",
    "\n",
    "## update_mini_batch\n",
    "Update the network's weights and biases by applying gradient descent using backpropagation to a single mini batch. The `mini_batch` is a list of tuples `(x, y)`, and `eta` is the learning rate.\n",
    "\n",
    "## backdrop\n",
    "Return a tuple `(nabla_b, nabla_w)` representing the gradient for the cost function C_x.  `nabla_b` and `nabla_w` are layer-by-layer lists of numpy arrays, similar to `self.biases` and `self.weights`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(training_data, epochs, mini_batch_size, eta, test_data=None):\n",
    "    n = training_data.shape[0]\n",
    "    \n",
    "    for j in range(epochs):\n",
    "        np.random.shuffle(training_data)\n",
    "        \n",
    "        mini_batches = [training_data[k:k+mini_batch_size] for k in range(0, n, mini_batch_size)]\n",
    "        \n",
    "        for mini_batch in mini_batches:\n",
    "            update_mini_batch(mini_batch, eta)\n",
    "            \n",
    "        if test_data is not None:\n",
    "            n_test = test_data.shape[0]\n",
    "            evaluation = evaluate(test_data)\n",
    "            print(f'Epoch {j:02d}: {evaluation}/{n_test}')\n",
    "        else:\n",
    "            print(f'Epoch {j:02d} complete')\n",
    "\n",
    "\n",
    "def update_mini_batch(mini_batch, eta):\n",
    "    global biases, weights\n",
    "    \n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "\n",
    "    for x, y in mini_batch:\n",
    "        delta_nabla_b, delta_nabla_w = backprop(x, y)\n",
    "        nabla_b = [nb+dnb for nb, dnb in zip(nabla_b, delta_nabla_b)]\n",
    "        nabla_w = [nw+dnw for nw, dnw in zip(nabla_w, delta_nabla_w)]\n",
    "\n",
    "    n_batch = len(mini_batch)\n",
    "    \n",
    "    weights = [w-eta/n_batch*nw for w, nw in zip(weights, nabla_w)]\n",
    "    biases  = [b-eta/n_batch*nb for b, nb in zip(biases,  nabla_b)]\n",
    "\n",
    "\n",
    "def backprop(x, y):\n",
    "    nabla_b = [np.zeros(b.shape) for b in biases]\n",
    "    nabla_w = [np.zeros(w.shape) for w in weights]\n",
    "    \n",
    "    # feed forward\n",
    "    activation = x\n",
    "    \n",
    "    activations = [x] # list to store all the activations, layer by layer\n",
    "    zs = [] # list to store all the z vectors, layer by layer\n",
    "    \n",
    "    for b, w in zip(biases, weights):\n",
    "        z = np.dot(w, activation) + b\n",
    "        zs.append(z)\n",
    "        activation = sigmoid(z)\n",
    "        activations.append(activation)\n",
    "        \n",
    "    # backward pass\n",
    "    \n",
    "    # cost dericative\n",
    "    delta = (activations[-1] - y) * sigmoid_prime(zs[-1])\n",
    "    \n",
    "    nabla_b[-1] = delta\n",
    "    nabla_w[-1] = np.dot(delta, activations[-2].transpose())\n",
    "    \n",
    "    for l in range(2, num_layers):\n",
    "        delta = np.dot(weights[-l+1].transpose(), delta) * sigmoid_prime(zs[-l])\n",
    "        \n",
    "        nabla_b[-l] = delta\n",
    "        nabla_w[-l] = np.dot(delta, activations[-l-1].transpose())\n",
    "        \n",
    "    return nabla_b, nabla_w\n",
    "        \n",
    "\n",
    "def sigmoid_prime(z):\n",
    "    s = sigmoid(z)\n",
    "    return s * (1 - s)\n",
    "\n",
    "\n",
    "def evaluate(test_data):\n",
    "    test_results = [(np.argmax(feedforward(x)), y) for x, y in test_data]\n",
    "    return sum(int(x == y) for x, y in test_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = np.array(list(zip(xx_train, yy_train)))\n",
    "test_input = np.array(list(zip(xx_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 7727 10000\n",
      "Epoch 1: 7799 10000\n",
      "Epoch 2: 7851 10000\n",
      "Epoch 3: 7816 10000\n",
      "Epoch 4: 7857 10000\n",
      "Epoch 5: 7891 10000\n",
      "Epoch 6: 7904 10000\n",
      "Epoch 7: 7895 10000\n",
      "Epoch 8: 7904 10000\n",
      "Epoch 9: 7902 10000\n",
      "Epoch 10: 7945 10000\n",
      "Epoch 11: 7968 10000\n",
      "Epoch 12: 8003 10000\n",
      "Epoch 13: 8676 10000\n",
      "Epoch 14: 8715 10000\n",
      "Epoch 15: 8709 10000\n",
      "Epoch 16: 8725 10000\n",
      "Epoch 17: 8726 10000\n",
      "Epoch 18: 8736 10000\n",
      "Epoch 19: 8735 10000\n",
      "Epoch 20: 8734 10000\n",
      "Epoch 21: 8743 10000\n",
      "Epoch 22: 8745 10000\n",
      "Epoch 23: 8752 10000\n",
      "Epoch 24: 8754 10000\n",
      "Epoch 25: 8747 10000\n",
      "Epoch 26: 8746 10000\n",
      "Epoch 27: 8746 10000\n",
      "Epoch 28: 8745 10000\n",
      "Epoch 29: 8754 10000\n"
     ]
    }
   ],
   "source": [
    "SGD(train_input, epochs=30, mini_batch_size=10, eta=3.0, test_data=test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8754"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx_train.shape\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation of the validation dataset: 9678/10000,  accuracy: 96.78%\n"
     ]
    }
   ],
   "source": [
    "xx_valid = x_valid.reshape((-1, 784, 1))\n",
    "valid_input = np.array(list(zip(xx_valid, y_valid)))\n",
    "\n",
    "evaluation = evaluate(valid_input)\n",
    "num_valid = xx_valid.shape[0]\n",
    "accuracy = float(evaluation) / num_valid * 100\n",
    "\n",
    "print(f'Evaluation of the validation dataset: {evaluation}/{num_valid},  accuracy: {accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 8746 10000\n",
      "Epoch 1: 8754 10000\n",
      "Epoch 2: 8762 10000\n",
      "Epoch 3: 8767 10000\n",
      "Epoch 4: 8782 10000\n",
      "Epoch 5: 8811 10000\n",
      "Epoch 6: 9608 10000\n",
      "Epoch 7: 9612 10000\n",
      "Epoch 8: 9618 10000\n",
      "Epoch 9: 9626 10000\n",
      "Epoch 10: 9627 10000\n",
      "Epoch 11: 9632 10000\n",
      "Epoch 12: 9657 10000\n",
      "Epoch 13: 9636 10000\n",
      "Epoch 14: 9648 10000\n",
      "Epoch 15: 9649 10000\n",
      "Epoch 16: 9644 10000\n",
      "Epoch 17: 9640 10000\n",
      "Epoch 18: 9640 10000\n",
      "Epoch 19: 9640 10000\n",
      "Epoch 20: 9657 10000\n",
      "Epoch 21: 9635 10000\n",
      "Epoch 22: 9635 10000\n",
      "Epoch 23: 9645 10000\n",
      "Epoch 24: 9648 10000\n",
      "Epoch 25: 9648 10000\n",
      "Epoch 26: 9647 10000\n",
      "Epoch 27: 9647 10000\n",
      "Epoch 28: 9649 10000\n",
      "Epoch 29: 9637 10000\n"
     ]
    }
   ],
   "source": [
    "SGD(train_input, epochs=30, mini_batch_size=10, eta=3.0, test_data=test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
